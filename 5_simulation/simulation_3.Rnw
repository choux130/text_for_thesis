\documentclass{article}
\usepackage[letterpaper, total={6in, 8in}]{geometry} %size of paper
\usepackage{indentfirst} %indent after section 
\usepackage{graphicx}
\usepackage{amsmath} %number figure based on subsection also
\numberwithin{figure}{subsection} %number figure based on subsection also
\numberwithin{table}{subsection} %number table based on subsection also
\usepackage{caption}
\captionsetup[figure]{labelfont=bf}
\captionsetup[table]{labelfont=bf,position=below}

\setlength{\parindent}{8ex}
\setlength{\parskip}{2em}
\renewcommand{\baselinestretch}{2.0}

\begin{document}
\setcounter{section}{3} 
\section{Simulation}
\setcounter{subsection}{2}
\subsection{Results for the simulation study}
After repeating sampling with and without replacement, sampling distribution of each candidate estimate can be constructed and their Biase, Variance and MSE can also be obtained. Figure~\ref{fig_dis_size_wr}, Figure~\ref{fig_dis_size_wor}, Table~\ref{tab_size_est} and Table~\ref{tab_per_est} shows that when sampling ``with'' replacement, MLE and Second Order Taylor's Approximation are always the best esitmate for ${\theta}_{A}$ and ${\theta}_{P}$ and when sample size becomes larger, their performance on Variance would also become better. As for the performance of Arithmetric Mean, like our expectation, severely overestimates the true mean no matter how sample size changes. Conversly, when it is sampling ``without'' replacement, the performance of MLE and Second Order Taylor's Approximation estimate are not worse only when the sample size compared to population size is small because when sample size is small, sampling without replacement is similar to sampling with replacement. For Arithmetic Mean, even though its expected value approximates to the true mean as sample size becomes larger, it is still a biased estimate as long as the sample size is not equal to the population size.

To sum up, in this simulation, when it is sampling ``with'' replacement, MLE and the 2nd Order Taylor's Approximation estimate perform best and Arithmetic Mean has the worst performance. Nevertheless, MLE and 2nd Order Taylor's Approximation estimate can only be obtained under strong assumptions on distributions of Area and Circularity. Hence, we also include Weighted Mean in our following distribution for its sufficient performance and its nonparametric assumption. 

\begin{figure}[!htbp]
  \centering
<<echo=FALSE,warning=FALSE, message=FALSE,fig.width=8, fig.height=6>>=
#Sampling without replacement - Perimeter ####
datt=read.csv("/Users/chou/Google Drive/Spring2016/Plan B/final/clean_dat.csv",header=TRUE)

# SETTING ARGUMENTS 
N=2000
ratio=c(0.05,0.1,0.3,0.5,0.7,0.95)
n=N*ratio
mean.size=1000
runs=100

# SIMULATION, SAMPLING 
set.seed(12345)
sub.pop.area=rexp(N,rate=1/mean.size)
true.mean.size=mean(sub.pop.area) #985.7484

sample.mean.area=array(NA, dim=c(runs,3,length(n)))
dimnames(sample.mean.area)=list(NULL,c("AM","WM","MLE"),n)
for (j in 1:length(n)){
  for (i in 1:runs){
    sample=sample(sub.pop.area,n[j],prob=sub.pop.area,replace=TRUE)
    
    w=sum(sample)/sample 
    
    a.m=mean(sample) #Arithmetic mean
    w.m=sum(sample*w)/sum(w) # Weighted mean
    a.mm=mean(sample)/2 #MLE 

    sample.mean.area[i,,j]=c(a.m,w.m,a.mm)
  }
}

library(reshape2)
sample.mean.l.area=melt(sample.mean.area)
colnames(sample.mean.l.area)=c("nn","estimate","s.size","value")

library(ggplot2)
image.area=list()
for (i in 1:length(n)){
  pp=ggplot(sample.mean.l.area[sample.mean.l.area$s.size==n[i],], aes(x=value, colour=estimate)) + 
    geom_line(aes(color=estimate), stat="density", size=0.6)+
    geom_vline(xintercept = true.mean.size, colour= "#D55E00", size=0.9, linetype=2)+
    ggtitle(paste("Sampling distributions \n n= ",n[i], ", Ratio= ",ratio[i], ",", "theta_A","=",round(true.mean.size,2)))+
    labs(x = expression(paste(theta["A"])))
  image.area[[i]]=pp
}

if(!require("Rmisc")){
  install.packages("Rmisc",dependencies = TRUE)
}
library(Rmisc)
multiplot(plotlist = image.area, cols = 2)
@
\caption{Sampling Distributions for Estimates of Mean Size (WR)}
  \label{fig_dis_size_wr}
\end{figure}


<<echo=FALSE, results='asis', message = FALSE>>=
# LISTS for ESTIMATES ####
array.mean.area=array(NA,dim=c(3,3,length(n)))
for (i in 1:length(n)){
  array.mean.area[,1,i]=apply(sample.mean.area[,,i],2,mean)-true.mean.size
  array.mean.area[,2,i]=apply(sample.mean.area[,,i],2,var)
  array.mean.area[,3,i]=array.mean.area[,1,i]^2+array.mean.area[,2,i]
}

dimnames(array.mean.area)=list(c("AM","WM","MLE"),c("Bias","Variance","MSE"),
                               c(paste("true.mean.size=",round(true.mean.size,3),"n=",n,sep=" ")))
x=vector()
for (i in 1:length(n)) x=rbind(x,array.mean.area[,,i])
x=round(x,1)
n=vector()
for (i in 1:length(ratio)) n=c(n,ratio[i]*N,NA,NA)
Estimate=rownames(x)
t_size_inf=cbind(n,Estimate,x)
@

\begin{figure}[!htbp]
  \centering
<<echo=FALSE,warning=FALSE, message=FALSE,fig.width=8, fig.height=6>>=
# SETTING ARGUMENTS ####
N=2000
ratio=c(0.05,0.1,0.3,0.5,0.7,0.95)
n=N*ratio
mean.size=1000
runs=100

# SIMULATION, SAMPLING ####
set.seed(12345)
sub.pop.area=rexp(N,rate=1/mean.size)
true.mean.size=mean(sub.pop.area)#985.7484

sample.mean.area=array(NA, dim=c(runs,3,length(n)))
dimnames(sample.mean.area)=list(NULL,c("AM","WM","MLE"),n)
for (j in 1:length(n)){
  for (i in 1:runs){
    sample=sample(sub.pop.area,n[j],prob=sub.pop.area,replace=FALSE)
  
    w=sum(sample)/sample 
    
    a.m=mean(sample) #Arithmetic mean
    w.m=sum(sample*w)/sum(w) # Weighted mean
    a.mm=mean(sample)/2 #MLE 

    sample.mean.area[i,,j]<-c(a.m,w.m,a.mm)
  }
}
library(reshape2)
sample.mean.l.area=melt(sample.mean.area)
colnames(sample.mean.l.area)=c("nn","estimate","s.size","value")

library(ggplot2)
image.area=list()
for (i in 1:length(n)){
  pp=ggplot(sample.mean.l.area[sample.mean.l.area$s.size==n[i],], aes(x=value, colour=estimate)) + 
    geom_line(aes(color=estimate), stat="density", size=0.6)+
    geom_vline(xintercept = true.mean.size, colour= "#D55E00", size=0.9, linetype=2)+
    ggtitle(paste("Sampling distributions \n n= ",n[i], ", ratio= ",ratio[i], ", thetaA","=",round(true.mean.size,2)))+
    labs(x = expression(paste(theta["A"])))
  image.area[[i]]=pp
}

if(!require("Rmisc")){
  install.packages("Rmisc",dependencies = TRUE)
}
library(Rmisc)
multiplot(plotlist = image.area, cols = 2)
@
\caption{Sampling Distributions for Estimates of Mean Size (WOR)}
  \label{fig_dis_size_wor}
\end{figure}

<<echo=FALSE, results='asis', message = FALSE>>=
# LISTS for ESTIMATES ####
array.mean.area=array(NA,dim=c(3,3,length(n)))
for (i in 1:length(n)){
  array.mean.area[,1,i]=apply(sample.mean.area[,,i],2,mean)-true.mean.size
  array.mean.area[,2,i]=apply(sample.mean.area[,,i],2,var)
  array.mean.area[,3,i]=array.mean.area[,1,i]^2+array.mean.area[,2,i]
}

dimnames(array.mean.area)=list(c("AM","WM","MLE"),c("Bias","Variance","MSE"),
                               c(paste("true.mean.size=",round(true.mean.size,3),"n=",n,sep=" ")))
x=vector()
for (i in 1:length(n)) x=rbind(x,array.mean.area[,,i])
x=round(x,1)
n=vector()
for (i in 1:length(ratio)) n=c(n,ratio[i]*N,NA,NA)
Estimate=rownames(x)
t_size_f=cbind(n,Estimate,x)
library(Hmisc)
latex(cbind(t_size_inf,t_size_f),rowname = NULL, file= "", 
      label="tab_size_est",
      col.just= rep("r",10), caption.loc=c("bottom"),
    cgroup=c("Sampling with Replacement","Sampling without Replacement"),
    caption="Performance Table for Area")
@

\begin{figure}[!htbp]
  \centering
<<echo=FALSE,warning=FALSE, message=FALSE,fig.width=8, fig.height=6>>=
# SETTING ARGUMENTS (Same us size_infinite) ####
N=2000
ratio=c(0.05,0.1,0.3,0.5,0.7,0.95)
n=N*ratio
mean.size=1000
runs=1000

sh1=15
sh2=5

# SIMULATION, SAMPLING ####
set.seed(12345)
sub.pop.area=rexp(N,rate=1/mean.size)
true.mean.size=mean(sub.pop.area) #985.7484

sub.pop.cir=rbeta(length(sub.pop.area),shape1=sh1,shape2=sh2)
true.mean.cir=mean(sub.pop.cir) #0.7515133

sub.pop.per=sqrt(4*pi)*sqrt(sub.pop.area/sub.pop.cir)
true.mean.per=mean(sub.pop.per) #114.2401

sim.data=data.frame(sub.pop.area,sub.pop.per,sub.pop.cir)
colnames(sim.data)=c("Area","Perimeter","Circularity")
par(mfrow=c(1,1))

sample.mean.per=array(NA, dim=c(runs,4,length(n)))
dimnames(sample.mean.per)=list(NULL,c("AM","WM","2_ord_approx","delta.m"),n)
for (j in 1:length(n)){
  for (i in 1:runs){
    sample=sim.data[sample(1:dim(sim.data)[1],n[j],prob=sim.data[,1],replace=TRUE),]
    
    w=sum(sample$Area)/sample$Area 
    c.m=mean(sample$Circularity)
    a.m=mean(sample$Area) 
    v.m=var(sample$Area)
    v.c=var(sample$Circularity)
    
    sh1.h=c.m^2*(1-c.m)/v.c - c.m
    sh2.h=c.m*(1-c.m)^2/v.c -(1-c.m)
    
    p.m=mean(sample$Perimeter) #Arithmetic mean
    p.w.m=sum(sample$Perimeter*w)/sum(w) # Weighted mean
    
    delta.m=sqrt(4*pi)*(sqrt(a.m/(2*c.m)))
    
    p_2_approx=sqrt(4*pi)*(sqrt(a.m/(2*c.m))-
                             (1/8)*(a.m/2)^(-3/2)*(c.m)^(-1/2)*(v.m/2)+
                             (3/8)*(a.m/2)^(1/2)*(c.m)^(-5/2)*(v.c)) 
    
    sample.mean.per[i,,j]=c(p.m, p.w.m, p_2_approx, delta.m)
  }
}
library(reshape2)
sample.mean.l.per=melt(sample.mean.per)
colnames(sample.mean.l.per)=c("nn","estimate","s.size","value")


library(ggplot2)
image.per=list()
for (i in 1:length(n)){
  pp=ggplot(sample.mean.l.per[sample.mean.l.per$s.size==n[i],], aes(x=value, colour=estimate)) + 
    geom_line(aes(color=estimate), stat="density", size=0.6)+
    geom_vline(xintercept = true.mean.per, colour= "#D55E00", size=0.9, linetype=2)+
    ggtitle(paste("Sampling distributions \n n= ",n[i], ", ratio= ",ratio[i], ", thetaP","=",
                  round(true.mean.per,2)))+
    labs(x = expression(paste(theta["P"])))
  image.per[[i]]=pp
}

if(!require("Rmisc")){
  install.packages("Rmisc")
}
library(Rmisc)
multiplot(plotlist = image.per, cols = 2)
@
\caption{Sampling Distributions for Estimates of Mean Perimeter (WR)}
  \label{fig_dis_per_wr}
\end{figure}

<<echo=FALSE, results='asis', message = FALSE>>=
# LISTS for ESTIMATES ####
array.mean.per=array(NA,dim=c(3,3,length(n)))
for (i in 1:length(n)){
  array.mean.per[,1,i]=apply(sample.mean.per[,,i],2,mean)-true.mean.per
  array.mean.per[,2,i]=apply(sample.mean.per[,,i],2,var)
  array.mean.per[,3,i]=array.mean.per[,1,i]^2+array.mean.per[,2,i]
}

dimnames(array.mean.per)=list(c("AM","WM","2nd Approx."),c("Bias","Variance","MSE"),
                               c(paste("true.mean.per=",round(true.mean.per,3),"n=",n,sep=" ")))

x=vector()
for (i in 1:length(n)) x=rbind(x,array.mean.per[,,i])
x=round(x,1)
n=vector()
for (i in 1:length(ratio)) n=c(n,ratio[i]*N,NA,NA)
Estimate=rownames(x)
t_per_inf=cbind(n,Estimate,x)
@


\begin{figure}[!htbp]
  \centering
<<echo=FALSE,warning=FALSE, message=FALSE,fig.width=8, fig.height=6>>=
# SETTING ARGUMENTS (Same us size_infinite) ####
N=2000
ratio=c(0.05,0.1,0.3,0.5,0.7,0.95)
n=N*ratio
mean.size=1000
runs=1000

sh1=15
sh2=5

# SIMULATION, SAMPLING ####
set.seed(12345)
sub.pop.area=rexp(N,rate=1/mean.size)
true.mean.size=mean(sub.pop.area) #985.7484

sub.pop.cir=rbeta(length(sub.pop.area),shape1=sh1,shape2=sh2)
true.mean.cir=mean(sub.pop.cir) #0.7515133

sub.pop.per=sqrt(4*pi)*sqrt(sub.pop.area/sub.pop.cir)
true.mean.per=mean(sub.pop.per) #114.2401

sim.data=data.frame(sub.pop.area,sub.pop.per,sub.pop.cir)
colnames(sim.data)=c("Area","Perimeter","Circularity")
par(mfrow=c(1,1))

sample.mean.per=array(NA, dim=c(runs,3,length(n)))
dimnames(sample.mean.per)=list(NULL,c("AM","WM","2_ord_approx"),n)
for (j in 1:length(n)){
  for (i in 1:runs){
    sample=sim.data[sample(1:dim(sim.data)[1],n[j],prob=sim.data[,1],replace=FALSE),]
    
    w=sum(sample$Area)/sample$Area 
    c.m=mean(sample$Circularity)
    a.m=mean(sample$Area) 
    v.m=var(sample$Area)
    v.c=var(sample$Circularity)
    
    sh1.h=c.m^2*(1-c.m)/v.c - c.m
    sh2.h=c.m*(1-c.m)^2/v.c -(1-c.m)
    
    p.m=mean(sample$Perimeter) #Arithmetic mean
    p.w.m=sum(sample$Perimeter*w)/sum(w) # Weighted mean
    
    a.m*beta(sh1.h-1,sh2.h)/beta(sh1.h,sh2.h)
    
    p_2_approx=sqrt(4*pi)*(sqrt(a.m/(2*c.m))-
                             (1/8)*(a.m/2)^(-3/2)*(c.m)^(-1/2)*(v.m/2)+
                             (3/8)*(a.m/2)^(1/2)*(c.m)^(-5/2)*(v.c)) 
    
    sample.mean.per[i,,j]=c(p.m, p.w.m, p_2_approx)
  }
}
library(reshape2)
sample.mean.l.per=melt(sample.mean.per)
colnames(sample.mean.l.per)=c("nn","estimate","s.size","value")


library(ggplot2)
image.per=list()
for (i in 1:length(n)){
  pp=ggplot(sample.mean.l.per[sample.mean.l.per$s.size==n[i],], aes(x=value, colour=estimate)) + 
    geom_line(aes(color=estimate), stat="density", size=0.6)+
    geom_vline(xintercept = true.mean.per, colour= "#D55E00", size=0.9, linetype=2)+
    ggtitle(paste("Sampling distributions \n n= ",n[i], ", ratio= ",ratio[i], ", thetaP","=",
                  round(true.mean.per,2)))+
    labs(x = expression(paste(theta["P"])))
  image.per[[i]]=pp
}

if(!require("Rmisc")){
  install.packages("Rmisc")
}
library(Rmisc)
multiplot(plotlist = image.per, cols = 2)
@
\caption{Sampling Distributions for Estimates of Mean Perimeter (WOR)}
  \label{fig_dis_per_wor}
\end{figure}

<<echo=FALSE, results='asis', message = FALSE>>=
# LISTS for ESTIMATES ####
array.mean.per=array(NA,dim=c(3,3,length(n)))
for (i in 1:length(n)){
  array.mean.per[,1,i]=apply(sample.mean.per[,,i],2,mean)-true.mean.per
  array.mean.per[,2,i]=apply(sample.mean.per[,,i],2,var)
  array.mean.per[,3,i]=array.mean.per[,1,i]^2+array.mean.per[,2,i]
}

dimnames(array.mean.per)=list(c("AM","WM","2nd Approx."),
                              c("Bias","Variance","MSE"),
                               c(paste("true.mean.per=",
                              round(true.mean.per,3),"n=",n,sep=" ")))

x=vector()
for (i in 1:length(n)) x=rbind(x,array.mean.per[,,i])
x=round(x,1)
n=vector()
for (i in 1:length(ratio)) n=c(n,ratio[i]*N,NA,NA)
Estimate=rownames(x)
t_per_f=cbind(n,Estimate,x)

latex(cbind(t_per_inf,t_per_f),rowname = NULL, file= "", 
       col.just= rep("r",10), caption.loc=c("bottom"),
       label="tab_per_est",
    cgroup=c("Sampling with Replacement","Sampling without Replacement"),
    caption="Performance Table for Perimeter")

@




\end{document}